# -*- coding: utf-8 -*-
"""Test04.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11XXPF3odGI2D0f5ZKcrBGAzX8viQiFB1
"""

import numpy as np
from sklearn.neighbors import KNeighborsClassifier
from sklearn import metrics
import matplotlib.pyplot as plt

# 닥스훈트의 길이와 높이 데이터
dach_length = [55, 57, 64, 63, 58, 49, 54, 61]
dach_height = [30, 31, 36, 30, 33, 25, 37, 34]

# 진돗개의 길이와 높이 데이터
jin_length = [56, 47, 56, 46, 49, 53, 52, 48]
jin_height = [52, 52, 50, 53, 50, 53, 49, 54]

j_data = np.column_stack((jin_length, jin_height))
j_label = np.ones(len(j_data))

d_data = np.column_stack((dach_length, dach_height))
d_label = np.zeros(len(d_data))

dogs = np.concatenate((d_data, j_data))
labels = np.concatenate((d_label, j_label))

newdata = [[52, 42]]
dog_classes = {0:'Dachshund', 1:'Jindo dog'}
k = 5 # k를 5으로 두고 kNN 분류기를 만들어 보자, 또 k =9 로 두고도 확인해 볼 것.
knn = KNeighborsClassifier(n_neighbors = k)
knn.fit(dogs, labels)
y_pred = knn.predict(newdata)
print('데이터', newdata, '판정 결과:', dog_classes[y_pred[0]])
distances, indexes = knn.kneighbors(newdata)
print('distances', distances, 'indexes:', indexes)
plt.scatter(newdata[0][0], newdata[0][1], s=100, marker='p', c='green', label='new Data')
plt.scatter(dach_length, dach_height, c='red', label='Dachshund')
plt.scatter(jin_length, jin_height,c='blue',marker='^', label='Jindo dog')
#draw_neighbor(dogs, indexes, k)